# Complete Code Flow: Why Database Saves Are Delayed

## The Complete Flow

### STEP 1: Articles Are Fetched (Every Second)
**File:** `finnhub_realtime_v2.py` lines 737-883

```python
def query_finnhub_for_news():
    # Called every second by WebSocket collector
    # ...
    articles = client.company_news(symbol, _from=yesterday, to=today)
    
    # Process new articles (top 3 only)
    for article in articles[:3]:
        article_data = {
            'headline': article.get('headline', ''),
            'summary': article.get('summary', ''),
            'symbol': symbol,
            'url': url,
            'published': article.get('datetime', 0)
        }
        
        # ‚ö° IMMEDIATELY QUEUED - NO DELAY HERE
        article_to_score_queue.put_nowait(article_data)
        queued += 1
        logger.info(f"Queued {symbol} article for scoring...")
```

**What happens:**
- ‚úÖ Articles fetched from API
- ‚úÖ **IMMEDIATELY** queued to `article_to_score_queue`
- ‚úÖ Returns immediately (non-blocking)
- ‚úÖ **No delay at this stage**

---

### STEP 2: Background Thread Scores Articles
**File:** `finnhub_realtime_v2.py` lines 664-706

```python
def scoring_worker():
    """Background thread that scores articles from queue."""
    while _scoring_thread_running:
        # Get article from queue (block for up to 1 second)
        article_data = article_to_score_queue.get(timeout=1.0)
        
        # ‚ö° SCORE IMMEDIATELY
        impact = score_article_with_ai(
            article_data['headline'],
            article_data['summary'],
            article_data['symbol']
        )
        
        # ‚ö° PUT IMPACT IN QUEUE IMMEDIATELY (BEFORE SAVE!)
        scored_article_queue.put(impact)
        
        # ‚ö†Ô∏è SAVE TO DATABASE (CAN FAIL/DELAY)
        try:
            save_article_to_db(article_data, impact)
        except Exception as e:
            logger.error(f"Error saving article to database: {e}")
            # ‚ö†Ô∏è CONTINUE EVEN IF SAVE FAILS!
            # Impact already applied to sentiment!
```

**What happens:**
- ‚úÖ Article scored immediately
- ‚úÖ **Impact put in queue BEFORE database save**
- ‚ö†Ô∏è Database save happens AFTER impact is queued
- ‚ö†Ô∏è **If save fails, impact still applied to sentiment!**

---

### STEP 3: Sentiment Score Updated (Real-Time)
**File:** `sentiment_realtime_v2.py` lines 419-433

```python
# Check for newly scored articles (from Finnhub thread)
impacts = get_scored_articles()  # Gets from scored_article_queue
if impacts:
    total_impact = sum(impacts)
    for article_impact in impacts:
        news_updated += article_impact  # ‚ö° APPLIED IMMEDIATELY
        logger.info(f"Applied Finnhub article impact: {article_impact:+.2f}")
```

**What happens:**
- ‚úÖ Impacts read from queue **immediately**
- ‚úÖ Applied to sentiment score **in real-time**
- ‚úÖ **Happens BEFORE database save completes**
- ‚úÖ **Sentiment moves even if save fails!**

---

### STEP 4: Database Save (WITH RETRY LOGIC - THIS IS WHERE DELAYS HAPPEN)
**File:** `finnhub_realtime_v2.py` lines 270-550

```python
def save_article_to_db(article_data, impact):
    max_retries = 3
    retry_delay = 0.5  # seconds
    
    for attempt in range(max_retries):
        try:
            # ... validation code ...
            
            # ‚ö†Ô∏è DATABASE SAVE ATTEMPT
            article, created = NewsArticle.objects.update_or_create(
                article_hash=article_hash,
                defaults={...}
            )
            
            # ‚úÖ SUCCESS - fetched_at set to NOW
            if created:
                logger.info(f"NEWSSAVING: ‚úÖ SAVED_NEW...")
            return article
            
        except IntegrityError as e:
            # ‚ö†Ô∏è RETRY ON CONSTRAINT VIOLATION
            logger.warning(f"NEWSSAVING: üîÑ DUPLICATE attempt={attempt + 1}/{max_retries}")
            if attempt < max_retries - 1:
                time.sleep(retry_delay)  # ‚ö†Ô∏è DELAY: 0.5s, 1s, 2s
                retry_delay *= 2
                continue  # ‚ö†Ô∏è RETRY LATER
            
        except OperationalError as e:
            # ‚ö†Ô∏è RETRY ON DATABASE ERROR (connection, deadlock, timeout)
            logger.warning(f"NEWSSAVING: üîÑ {error_type} attempt={attempt + 1}/{max_retries}")
            if attempt < max_retries - 1:
                time.sleep(retry_delay)  # ‚ö†Ô∏è DELAY: 0.5s, 1s, 2s
                retry_delay *= 2
                continue  # ‚ö†Ô∏è RETRY LATER
            
        except DatabaseError as e:
            # ‚ö†Ô∏è RETRY ON ANY DATABASE ERROR
            logger.warning(f"NEWSSAVING: üîÑ DATABASE_ERROR attempt={attempt + 1}/{max_retries}")
            if attempt < max_retries - 1:
                time.sleep(retry_delay)  # ‚ö†Ô∏è DELAY: 0.5s, 1s, 2s
                retry_delay *= 2
                continue  # ‚ö†Ô∏è RETRY LATER
    
    # ‚ùå ALL RETRIES FAILED - RETURN NONE
    logger.error(f"NEWSSAVING: ‚ùå FAILED after {max_retries} attempts")
    return None
```

**What happens:**
- ‚ö†Ô∏è **First attempt fails** (database busy/connection issue)
- ‚ö†Ô∏è **Wait 0.5 seconds**, retry
- ‚ö†Ô∏è **Second attempt fails** (still busy)
- ‚ö†Ô∏è **Wait 1 second**, retry
- ‚ö†Ô∏è **Third attempt fails** (still busy)
- ‚ö†Ô∏è **Wait 2 seconds**, retry
- ‚úÖ **Fourth attempt succeeds** ‚Üí `fetched_at` = NOW (could be hours later!)

---

### STEP 5: The `fetched_at` Field Behavior
**File:** `api/models.py` line 261

```python
class NewsArticle(models.Model):
    fetched_at = models.DateTimeField(auto_now_add=True)
```

**What `auto_now_add=True` means:**
- ‚úÖ **CREATE:** `fetched_at` = current time (when first saved successfully)
- ‚ùå **UPDATE:** `fetched_at` = **NOT CHANGED** (stays as original creation time)

**What `update_or_create()` does:**
```python
article, created = NewsArticle.objects.update_or_create(
    article_hash=article_hash,
    defaults={...}
)
```

- If article **doesn't exist** ‚Üí **CREATE** ‚Üí `fetched_at` = NOW ‚úÖ
- If article **already exists** ‚Üí **UPDATE** ‚Üí `fetched_at` = **UNCHANGED** ‚ùå

---

## The Complete Timeline Example

### What Actually Happens:

```
9:00:00 AM EST - Article fetched from API
9:00:00 AM EST - Article queued for scoring ‚úÖ
9:00:05 AM EST - Article scored ‚úÖ
9:00:05 AM EST - Impact put in scored_article_queue ‚úÖ
9:00:05 AM EST - Sentiment score updated ‚úÖ MOVEMENT HAPPENS!
9:00:05 AM EST - Try to save to database...
9:00:05 AM EST - ‚ùå Database save FAILS (connection timeout)
9:00:05 AM EST - Wait 0.5 seconds...
9:00:06 AM EST - Retry save...
9:00:06 AM EST - ‚ùå Database save FAILS (deadlock)
9:00:06 AM EST - Wait 1 second...
9:00:07 AM EST - Retry save...
9:00:07 AM EST - ‚ùå Database save FAILS (still busy)
9:00:07 AM EST - Wait 2 seconds...
9:00:09 AM EST - Retry save...
9:00:09 AM EST - ‚ùå Database save FAILS (connection issue)
9:00:09 AM EST - Return None (all retries exhausted)

... hours pass, database connection stabilizes ...

2:00:00 PM EST - Article somehow gets saved (maybe retry from another thread?)
2:00:00 PM EST - ‚úÖ SAVE SUCCEEDS ‚Üí fetched_at = 2:00 PM EST
```

**Result:**
- ‚úÖ Sentiment score moved at **9:00:05 AM**
- ‚ùå `fetched_at` shows **2:00:00 PM**
- ‚ùå **5-hour discrepancy!**

---

## Why Saves Cluster in Afternoon

### Scenario: Database Connection Issues

**Morning (9:00 AM - 1:00 PM):**
- Articles fetched ‚úÖ
- Articles scored ‚úÖ
- Impacts applied ‚úÖ
- **Database saves FAIL** (connection issues, timeouts, deadlocks)
- Retries exhausted, saves abandoned

**Afternoon (2:00 PM - 3:00 PM):**
- Database connection stabilizes
- Some retry mechanism succeeds
- **Batch of articles finally saved**
- `fetched_at` = 2:00 PM - 3:00 PM (but articles processed hours earlier)

---

## The Critical Code Sections

### 1. Impact Applied BEFORE Save (Line 696)
```python
# Put result in scored queue
scored_article_queue.put(impact)  # ‚ö° HAPPENS FIRST

# Save article to database
save_article_to_db(article_data, impact)  # ‚ö†Ô∏è HAPPENS AFTER
```

### 2. Save Can Fail Silently (Line 692)
```python
try:
    save_article_to_db(article_data, impact)
except Exception as e:
    logger.error(f"Error saving article to database: {e}")
    # Continue even if save fails - don't break sentiment calculation
    # ‚ö†Ô∏è IMPACT ALREADY APPLIED!
```

### 3. Retry Logic Causes Delays (Lines 488-550)
```python
except OperationalError as e:
    if attempt < max_retries - 1:
        time.sleep(retry_delay)  # ‚ö†Ô∏è DELAYS HERE
        retry_delay *= 2  # Exponential backoff
        continue  # Retry later
```

### 4. `fetched_at` Only Set on Create (Model line 261)
```python
fetched_at = models.DateTimeField(auto_now_add=True)
# Only set when article is FIRST created
# NOT updated on subsequent updates
```

---

## Why This Design Exists

### The Intent:
1. **Don't block sentiment calculation** - sentiment updates happen immediately
2. **Resilient to database issues** - retries prevent data loss
3. **Non-blocking** - scoring thread doesn't wait for database

### The Problem:
1. **`fetched_at` doesn't reflect actual fetch time** - it reflects save time
2. **Delayed saves create misleading timestamps** - clustered in afternoon
3. **No tracking of actual fetch time** - only save time is recorded

---

## What Needs to Change

### Current Flow:
```
Fetch ‚Üí Queue ‚Üí Score ‚Üí Queue Impact ‚Üí Apply Impact ‚Üí Try Save ‚Üí Retry ‚Üí Save
  ‚úÖ      ‚úÖ      ‚úÖ         ‚úÖ            ‚úÖ           ‚ö†Ô∏è        ‚ö†Ô∏è      ‚úÖ
```

### Problem:
- `fetched_at` = Save time (can be hours after fetch)
- No record of actual fetch time
- Sentiment moves before save completes

### Solution Options:

1. **Track actual fetch time separately:**
   ```python
   api_fetched_at = models.DateTimeField()  # When fetched from API
   queued_at = models.DateTimeField()  # When queued
   scored_at = models.DateTimeField()  # When scored
   fetched_at = models.DateTimeField(auto_now_add=True)  # When saved (keep for compatibility)
   ```

2. **Save fetch time when queuing:**
   ```python
   article_data = {
       ...
       'api_fetched_at': timezone.now(),  # Track actual fetch time
   }
   ```

3. **Make saves synchronous (but slower):**
   - Wait for save to complete before queuing impact
   - Blocks sentiment calculation
   - Not recommended (defeats purpose of async design)

---

## Summary

**The delay happens because:**

1. ‚úÖ Articles are fetched and processed **immediately** (explains sentiment movements)
2. ‚ö†Ô∏è Database saves have **retry logic** (3 attempts with exponential backoff)
3. ‚ö†Ô∏è Saves can **fail and retry later** (hours later)
4. ‚ö†Ô∏è `fetched_at` reflects **save time**, not fetch time
5. ‚ö†Ô∏è When saves finally succeed, `fetched_at` = current time (afternoon)
6. ‚úÖ But articles were **actually processed hours earlier** (morning)

**The code is working as designed** - it prioritizes real-time sentiment updates over database persistence. The `fetched_at` field just doesn't accurately represent when articles were actually fetched and processed.

